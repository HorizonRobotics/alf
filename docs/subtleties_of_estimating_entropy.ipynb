{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Subtleties of estimating entropy\n","\n","## Wei Xu\n","\n","For some algorithms, we need to calculate the entropy and its derivative. If\n","there is no analytic formula for the entropy, we can resort to sampling. Given\n","the definition of entropy:\n","\n","$$\n","\\begin{equation*}\n","H(p) = E_{x\\sim p_\\theta}(-\\log p_\\theta(x))\n","\\end{equation*}\n","$$\n","\n","We can see that $-\\log p_{\\theta}(x)$ is an unbiased estimator of $H$ if $x$ is\n","sampled from $p_{\\theta}$. It is tempting to use\n","$-\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}$ as an estimator of\n","$\\frac{\\partial H}{\\partial\\theta}$. However, it is wrong, as shown in the\n","following:\n","\n","$$\n","\\begin{equation*}\n","E_{x\\sim p_\\theta}\\left(\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}\\right)\n"," = \\int \\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta} p_\\theta(x) dx\n"," = \\int \\frac{\\partial p_\\theta(x)}{\\partial\\theta} dx\n"," = \\frac{\\partial}{\\partial\\theta} \\int p_\\theta(x) dx\n"," = \\frac{\\partial 1}{\\partial\\theta} = 0\n","\\end{equation*}\n","$$\n","\n","We need to actually go through the process of calculating the derivative to get\n","the unbiased estimator of $\\frac{\\partial H}{\\partial\\theta}$:\n","\n","$$\n","\\begin{array}{ll}\n","\\frac{\\partial H}{\\partial\\theta}\n","&=&-\\frac{\\partial}{\\partial\\theta}\\int \\log p_\\theta(x) p_\\theta(x) dx \\\\\n","&=& - \\int \\left(\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}p_\\theta(x)\n","    + \\log p_\\theta(x) \\frac{\\partial p_\\theta(x)}{\\partial\\theta}\\right) dx \\\\\n","&=& - \\int \\left(\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}p_\\theta(x)\n","     + \\log p_\\theta(x) \\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta} p_\\theta(x)\\right) dx \\\\\n","&=& - \\int (1+\\log p_\\theta(x))\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta} p_\\theta(x) dx \\\\\n","&=& -E_{x\\sim p_\\theta}\\left(\\log p_\\theta(x)\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}\\right)\n","    -E_{x\\sim p_\\theta}\\left(\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}\\right) \\\\\n","&=& -\\frac{1}{2}E_{x\\sim p_\\theta}\\left(\\frac{\\partial}{\\partial\\theta}(\\log p_\\theta(x))^2\\right) \\\\\n","\\end{array}\n","$$\n","\n","This means that $-\\frac{1}{2}\\frac{\\partial}{\\partial\\theta}(\\log p_\\theta(x))^2$\n","is an unbiased estimator of $\\frac{\\partial H}{\\partial\\theta}$. Actually,\n","$-\\frac{1}{2}\\frac{\\partial}{\\partial\\theta}(c+\\log p_\\theta(x))^2$ is an\n","unbiased estimator for any constant $c$.\n","\n","For some distributions, the sample of $p_\\theta$ is generated by transforming\n","$\\epsilon \\sim q$ by $f_\\theta(\\epsilon)$, where $q$ is a fixed distribution and\n","$f_\\theta$ is a smooth bijective mapping. $p_\\theta(x)$ is implicitly defined by\n","$q$ and $f_\\theta$ as:\n","\n","$$\n","\\begin{equation*}\n","p_\\theta(x) = q(f_\\theta^{-1}(x)) / \\left|\\det \\left.\n","  \\frac{\\partial f_\\theta(\\epsilon)}{\\partial\\epsilon}\\right|\n","  _{\\epsilon=f_\\theta^{-1}(x)}\\right|\n","\\end{equation*}\n","$$\n","\n","Interestingly, when calculating $-\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}$,\n","if we treat $x$ as $x=f_\\theta(\\epsilon)$, we get an unbiased estimator of\n","$\\frac{\\partial H}{\\partial\\theta}$:\n","\n","$$\n","\\begin{array}{ll}\n","&& E_{x\\sim p_\\theta}\\left(-\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}\\right)\n","   = E_{\\epsilon \\sim q}\\left(-\\frac{\\partial\\log p_\\theta(f_\\theta(\\epsilon))}{\\partial\\theta}\\right) \\\\\n","&=& -\\frac{\\partial}{\\partial\\theta}E_{\\epsilon \\sim q}\\left(\\log p_\\theta(f_\\theta(\\epsilon))\\right)\n","    = -\\frac{\\partial}{\\partial\\theta}E_{x \\sim p_\\theta}\\left(\\log p_\\theta(x)\\right)\n","    = \\frac{\\partial}{\\partial\\theta}H(p)\n","\\end{array}\n","$$\n","\n","So we can use $-\\frac{\\partial\\log p_\\theta(x)}{\\partial\\theta}$ as an unbiased\n","estimator of $\\frac{\\partial H(p)}{\\partial\\theta}$ if $x=f_\\theta(\\epsilon)$\n","and we allow gradient to propagate through $x$ to $\\theta$."]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}