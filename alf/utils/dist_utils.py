# Copyright (c) 2019 Horizon Robotics. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import gin

import tensorflow_probability as tfp
import tensorflow as tf

from tf_agents.distributions.utils import SquashToSpecNormal


@gin.configurable
def estimated_entropy(dist: tfp.distributions.Distribution,
                      seed=None,
                      assume_reparametrization=False,
                      num_samples=1):
    """Estimate entropy by sampling.

    Use sampling to calculate entropy. The unbiased estimator for entropy is
    -log(p(x)) where x is an unbiased sample of p. However, the gradient of
    -log(p(x)) is not an unbiased estimator of the gradient of entropy. So we
    also calculate a value whose gradient is an unbiased estimator of the
    gradient of entropy. See entropy_estimator.pdf for detail.

    Args:
        dist (tfp.distribitions.Distribution): concerned distribution
        seed (Any): Any Python object convertible to string, supplying the
            initial entropy.
        assume_reparametrization (bool): assume the sample from continuous
            distribution is generated by transforming a fixed distribution
            by a parameterized function. If we can assume this,
            entropy_for_gradient will have lower variance. We make the default
            to be False to be safe.
        num_samples (int): number of random samples used for estimating entropy.
    Returns:
        tuple of (entropy, entroy_for_gradient). entropy_for_gradient is for
        calculating gradient
    """
    sample_shape = (num_samples, )
    single_action = dist.sample(sample_shape=sample_shape, seed=seed)
    if single_action.dtype.is_floating and assume_reparametrization:
        entropy = -dist.log_prob(single_action)
        entropy = tf.reduce_mean(entropy, axis=0)
        entropy_for_gradient = entropy
    else:
        entropy = -dist.log_prob(tf.stop_gradient(single_action))
        entropy_for_gradient = -0.5 * tf.math.square(entropy)
        entropy = tf.reduce_mean(entropy, axis=0)
        entropy_for_gradient = tf.reduce_mean(entropy_for_gradient, axis=0)
    return entropy, entropy_for_gradient


def entropy_with_fallback(distributions, action_spec, seed=None):
    """Computes total entropy of nested distribution.

    If entropy() of a distribution is not implemented, this function will
    fallback to use sampling to calculate the entropy. It returns two values:
    (entropy, entropy_for_gradient).
    There are two situations:
    * entropy() is implemented. entropy is same as entropy_for_gradient.
    * entropy() is not implemented. We use sampling to calculate entropy. The
        unbiased estimator for entropy is -log(p(x)). However, the gradient of
        -log(p(x)) is not an unbiased estimator of the gradient of entropy. So
        we also calculate a value whose gradient is an unbiased estimator of
        the gradient of entropy. See estimated_entropy() for detail.

    Example:
        with tf.GradientTape() as tape:
            ent, ent_for_grad = entropy_with_fall_back(dist, action_spec)
        tf.summary.scalar("entropy", ent)
        grad = tape.gradient(ent_for_grad, weight)

    Args:
        distributions (nested Distribution): A possibly batched tuple of
            distributions.
        action_spec (nested BoundedTensorSpec): A nested tuple representing the
            action spec.
        seed (Any): Any Python object convertible to string, supplying the
            initial entropy.
    Returns:
        tuple of (entroy, entropy_for_gradient). You should use entroy in
        situations where its value is needed, and entropy_for_gradient where
        you need to calculate the gradient of entropy.
    """
    seed_stream = tfp.distributions.SeedStream(
        seed=seed, salt='entropy_with_fallback')

    def _calc_outer_rank(dist: tfp.distributions.Distribution, action_spec):
        if isinstance(dist, SquashToSpecNormal):
            # SquashToSpecNormal does not implement the two necessary interface
            # functions of Distribution. So we have to use the original
            # distribution it transforms.
            # SquashToSpecNormal is used by NormalProjectionNetwork with
            # scale_distribution=True
            dist = dist.input_distribution
        return (dist.batch_shape.ndims + dist.event_shape.ndims -
                action_spec.shape.ndims)

    def _compute_entropy(dist: tfp.distributions.Distribution, action_spec):
        try:
            entropy = dist.entropy()
            entropy_for_gradient = entropy
        except NotImplementedError:
            entropy, entropy_for_gradient = estimated_entropy(
                dist, seed=seed_stream())
        outer_rank = _calc_outer_rank(dist, action_spec)
        rank = entropy.shape.ndims
        reduce_dims = list(range(outer_rank, rank))
        entropy = tf.reduce_sum(input_tensor=entropy, axis=reduce_dims)
        entropy_for_gradient = tf.reduce_sum(
            input_tensor=entropy_for_gradient, axis=reduce_dims)
        return entropy, entropy_for_gradient

    entropies = list(
        map(_compute_entropy, tf.nest.flatten(distributions),
            tf.nest.flatten(action_spec)))
    entropies_for_gradient = [eg for e, eg in entropies]
    entropies = [e for e, eg in entropies]

    return tf.add_n(entropies), tf.add_n(entropies_for_gradient)
