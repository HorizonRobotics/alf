# environment config
create_environment.env_name="CartPole-v0"
create_environment.num_parallel_environments=8

# algorithm config
ActorCriticAlgorithm.gradient_clipping=10.0
ActorCriticLoss.entropy_regularization=0.001
ActorCriticLoss.gamma=0.98
ActorCriticLoss.td_error_loss_fn=@element_wise_huber_loss
ActorCriticLoss.use_gae=True
ActorCriticLoss.use_td_lambda_return=True
create_algorithm.actor_fc_layers=(100,)
create_algorithm.value_fc_layers=(100,)
create_algorithm.learning_rate=0.001

# training config
on_policy_trainer.train.train_interval=8
on_policy_trainer.train.num_iterations=1000000

train_eval.debug_summaries=1
