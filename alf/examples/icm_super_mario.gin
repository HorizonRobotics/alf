# icm on SuperMario

# environment config
# gym-retro>=0.7.0 is required for this experiment and also
#  a suitable `SuperMarioBros-Nes` rom should be obtain and imported (roms are not included in gym-retro)
#   see `https://retro.readthedocs.io/en/latest/getting_started.html#importing-roms` to import roms

create_environment.env_load_fn=@suite_mario.load
create_environment.env_name="SuperMarioBros-Nes"
create_environment.num_parallel_environments=30
suite_mario.load.state="Level1-1"
suite_mario.load.wrap_with_process=0

conv_layer_params=[(32,8,4),(64,4,2),(64,3,1)]

create_algorithm.use_rnns=False
create_algorithm.learning_rate=3e-5
create_algorithm.use_icm=1
create_algorithm.encoding_conv_layers=%conv_layer_params
create_algorithm.encoding_fc_layers=(256,)

EncodingNetwork.activation_fn=@tf.nn.elu
ICMAlgorithm.hidden_size=256

# value network layers
ValueNetwork.conv_layer_params=%conv_layer_params
create_algorithm.value_fc_layers=(256,256)
ValueNetwork.activation_fn=@tf.nn.elu

# actor network layers
ActorDistributionNetwork.conv_layer_params=%conv_layer_params
create_algorithm.actor_fc_layers=(256,256)
ActorDistributionNetwork.activation_fn=@tf.nn.elu
CategoricalProjectionNetwork.logits_init_output_factor=1e-10
ActorDistributionNetwork.discrete_projection_net=@CategoricalProjectionNetwork

ActorCriticLoss.entropy_regularization=0.01
ActorCriticAlgorithm.gradient_clipping=10.0
ActorCriticLoss.use_gae=True
ActorCriticLoss.use_td_lambda_return=True

tf.keras.layers.Conv2D.padding="same"
suite_mario.load.data_format="channels_first"
tf.keras.layers.Conv2D.data_format="channels_first"

# training config
on_policy_trainer.train.num_iterations=10000000
on_policy_trainer.train.summarize_grads_and_vars=1
on_policy_trainer.train.train_interval=32
on_policy_trainer.train.summary_interval=1
on_policy_trainer.train.use_tf_functions=1

OnPolicyDriver.observation_transformer=@image_scale_transformer
train_eval.debug_summaries=1
