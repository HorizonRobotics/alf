import alf.algorithms.actor_critic_algorithm
import alf.algorithms.agent
import alf.environments.suite_socialbot

# environment config
create_environment.env_name='SocialBot-SimpleNavigationDiscreteAction-v0'
create_environment.env_load_fn=@suite_socialbot.load
create_environment.num_parallel_environments=30
SimpleNavigation.resized_image_size=(84, 84)

# algorithm config
ActorCriticLoss.entropy_regularization=0.002
ActorCriticLoss.use_gae=True
ActorCriticLoss.use_td_lambda_return=True

actor/ActorDistributionNetwork.fc_layer_params=(256,)
actor/ActorDistributionNetwork.activation=@torch.nn.functional.elu_
actor/ActorDistributionNetwork.conv_layer_params=((16, 3, 2), (32, 3, 2))
CategoricalProjectionNetwork.logits_init_output_factor=1e-10
actor/ActorDistributionNetwork.discrete_projection_net_ctor=@CategoricalProjectionNetwork

value/ValueNetwork.fc_layer_params=(256,)
value/ValueNetwork.activation=@torch.nn.functional.elu_
value/ValueNetwork.conv_layer_params=((16, 3, 2), (32, 3, 2))

ac/AdamTF.lr=1e-4

ActorCriticAlgorithm.actor_network_ctor=@actor/ActorDistributionNetwork
ActorCriticAlgorithm.value_network_ctor=@value/ValueNetwork

import alf.algorithms.trac_algorithm
TracAlgorithm.ac_algorithm_cls=@ActorCriticAlgorithm
TracAlgorithm.action_dist_clip_per_dim=0.25

Agent.optimizer=@ac/AdamTF()
Agent.rl_algorithm_cls=@TracAlgorithm
TrainerConfig.data_transformer_ctor=[@FrameStacker, @ImageScaleTransformer]

# training config
TrainerConfig.unroll_length=100
TrainerConfig.algorithm_ctor=@Agent
TrainerConfig.num_iterations=100000
TrainerConfig.debug_summaries=True
TrainerConfig.summarize_grads_and_vars=1
TrainerConfig.summary_interval=100


