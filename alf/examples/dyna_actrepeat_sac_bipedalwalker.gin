include 'sac_bipedal_walker.gin'

import alf.algorithms.dynamic_action_repeat_algorithm
import alf.networks.preprocessors

OneStepTDLoss.gamma=1.0
K=5

q/QNetwork.preprocessing_combiner=@NestConcat()
q/QNetwork.fc_layer_params=(256, 256)
SacAlgorithm.q_network_cls=@q/QNetwork

DynamicActionRepeatAlgorithm.K=%K
DynamicActionRepeatAlgorithm.rl_algorithm_cls=@SacAlgorithm
DynamicActionRepeatAlgorithm.gamma=0.99

discrete/calc_default_target_entropy.min_prob=0.2
continuous/calc_default_target_entropy.min_prob=0.1
SacAlgorithm.target_entropy=(
    @discrete/calc_default_target_entropy,
    @continuous/calc_default_target_entropy)

Agent.rl_algorithm_cls=@DynamicActionRepeatAlgorithm
Agent.pass_config_to_rl_algorithm=True
Agent.skip_training=True
