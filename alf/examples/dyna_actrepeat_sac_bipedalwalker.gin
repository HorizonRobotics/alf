include 'sac_bipedal_walker.gin'

import alf.algorithms.dynamic_action_repeat_agent
import alf.networks.preprocessors

K=5

q/QNetwork.preprocessing_combiner=@NestConcat()
q/QNetwork.fc_layer_params=(256, 256)
SacAlgorithm.q_network_cls=@q/QNetwork

DynamicActionRepeatAgent.K=%K
DynamicActionRepeatAgent.rl_algorithm_cls=@SacAlgorithm
DynamicActionRepeatAgent.gamma=0.99

discrete/calc_default_target_entropy.min_prob=0.2
continuous/calc_default_target_entropy.min_prob=0.1
SacAlgorithm.target_entropy=(
    @discrete/calc_default_target_entropy,
    @continuous/calc_default_target_entropy)

TrainerConfig.algorithm_ctor=@DynamicActionRepeatAgent
TrainerConfig.debug_summaries=True

RewardNormalizer.clip_value=1.0
DynamicActionRepeatAgent.reward_normalizer_ctor=@RewardNormalizer