# MERLIN on deepmindlab rooms_collect_good_objects

import alf.algorithms.agent
import alf.algorithms.merlin_algorithm

# DeepmindLab is required.
# Stimuli dataset should be downloaded before building the python module.
# Follow instructions https://github.com/deepmind/lab/blob/master/data/brady_konkle_oliva2008/README.md
# And see https://github.com/deepmind/lab/blob/master/python/pip_package/README.md
# to build `DeepmindLab` Python module.

# environment config
import alf.environments.suite_dmlab

create_environment.env_load_fn=@suite_dmlab.load
create_environment.env_name="contributed/dmlab30/rooms_collect_good_objects_train"

# To test performance on `rooms_collect_good_objects_test`, just enable the following two lines
# create_environment.env_name="contributed/dmlab30/rooms_collect_good_objects_test"
# DeepmindLabEnv.config={'allowHoldOutLevels':'true'}

create_environment.num_parallel_environments=16
suite_dmlab.load.gym_env_wrappers=(@FrameResize, )
FrameResize.width=64
FrameResize.height=64

suite_dmlab.action_discretize.jump=()
suite_dmlab.action_discretize.crouch=()
suite_dmlab.action_discretize.look_down_up_pixels_per_frame=()
suite_dmlab.action_discretize.look_left_right_pixels_per_frame=(-30, 30)

# build deepmind_lab with  --define graphics=osmesa_or_glx
suite_dmlab.DeepmindLabEnv.renderer='hardware'

observation_spec=@get_observation_spec()

# algorithm config
LATENT_DIM=200

StackedLSTMCell.output_layers=-1
BottleneckBlock.v1_5=False

img_enc/ResnetEncodingNetwork.input_tensor_spec=%observation_spec

latent/TensorSpec.shape=(%LATENT_DIM,)
img_dec/ResnetDecodingNetwork.input_tensor_spec=@latent/TensorSpec()
img_dec/DecodingAlgorithm.loss_weight=100
img_dec/DecodingAlgorithm.decoder=@img_dec/ResnetDecodingNetwork()

MerlinAlgorithm.encoders=@img_enc/ResnetEncodingNetwork()
MerlinAlgorithm.decoders=@img_dec/DecodingAlgorithm()
MerlinAlgorithm.latent_dim=%LATENT_DIM
MerlinAlgorithm.lstm_size=(256, 256)
MerlinAlgorithm.memory_size=1350

# these are default hyper parameter used in the paper
#   we do not use them in this experiment
# ActorCriticLoss.gamma = 0.96
# ActorCriticLoss.use_gae=True
# ActorCriticLoss.use_td_lambda_return=True
# ActorCriticLoss.td_lambda=0.9
# ActorCriticLoss.entropy_regularization=0.01

ac/AdamTF.lr=1e-4

Agent.optimizer=@ac/AdamTF()
Agent.rl_algorithm_cls=@MerlinAlgorithm
Agent.observation_transformer=@image_scale_transformer
common.image_scale_transformer.min=0.0

# training config
TrainerConfig.unroll_length=20
TrainerConfig.algorithm_ctor=@Agent
TrainerConfig.num_iterations=50000
TrainerConfig.debug_summaries=True
TrainerConfig.summarize_grads_and_vars=1
TrainerConfig.summary_interval=10
TrainerConfig.evaluate=False
TrainerConfig.eval_interval=200
