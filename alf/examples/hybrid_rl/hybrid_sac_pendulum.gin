
include 'sac_pendulum.gin'

# Example config for Hybrid RL training.

TrainerConfig.mini_batch_size=32

# We can control when to start the online RL training with
# rl_train_after_update_steps

TrainerConfig.rl_train_after_update_steps=0

# We can control the update frequency of the online RL training
# wrt offline RL by setting rl_train_every_update_steps.

TrainerConfig.rl_train_every_update_steps=1

# Note that the following file used is just a dummy replay buffer
# file that only contains 3 pendulum trajectories for illustration
# purpose. It should be replaced with a larger replay buffer file
# in practice. This replay buffer is from an SAC agent.



# we can provide offline data from different experts, scenarios etc.
TrainerConfig.offline_buffer_dir=[
    "./hybrid_rl/replay_buffer_data/pendulum_replay_buffer_from_sac",
    "./hybrid_rl/replay_buffer_data/pendulum_replay_buffer_from_muzero"
]

# we can set the buffer length to be allocated for each offline buffer checkpoint
TrainerConfig.offline_buffer_length=100
