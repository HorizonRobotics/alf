import torch

import alf
import alf.algorithms.merlin_algorithm
import alf.environments.suite_carla

CameraSensor.image_size_x=200
CameraSensor.image_size_y=100
CameraSensor.fov=135

create_environment.env_name='Town01'
create_environment.env_load_fn=@suite_carla.load
create_environment.num_parallel_environments=4

use_batch_normalization=False
BottleneckBlock.with_batch_normalization=%use_batch_normalization
preproc_bn=True

suite_carla.Player.with_gnss_sensor=False

camera_spec = alf.nest.get_field(%observation_spec, "observation.camera")
radar_spec = alf.nest.get_field(%observation_spec, "observation.radar")
collision_spec = alf.nest.get_field(%observation_spec, "observation.collision")
#gnss_spec = alf.nest.get_field(%observation_spec, "observation.gnss")
imu_spec = alf.nest.get_field(%observation_spec, "observation.imu")
goal_spec = alf.nest.get_field(%observation_spec, "observation.goal")
velocity_spec = alf.nest.get_field(%observation_spec, "observation.velocity")
navigation_spec = alf.nest.get_field(%observation_spec, "observation.navigation")
prev_action_spec = alf.nest.get_field(%observation_spec, "prev_action")

observation_preprocessors = {
    "camera": @ResnetEncodingNetwork(input_tensor_spec=%camera_spec, output_size=%encoding_dim, output_activation=alf.math.identity, use_fc_bn=%preproc_bn),
    "radar": torch.nn.Sequential(alf.layers.Reshape([-1]), alf.layers.FC(@flattened_size(%radar_spec), %encoding_dim, use_bias=False, use_bn=%preproc_bn)),
    "collision": torch.nn.Sequential(alf.layers.Reshape([-1]), alf.layers.FC(@flattened_size(%collision_spec), %encoding_dim, use_bias=False, use_bn=%preproc_bn)),
    #"gnss": torch.nn.Sequential(alf.layers.Reshape([-1]), alf.layers.FC(@flattened_size(%gnss_spec), %encoding_dim, use_bias=False, use_bn=%preproc_bn)),
    "imu": torch.nn.Sequential(alf.layers.Reshape([-1]), alf.layers.FC(@flattened_size(%imu_spec), %encoding_dim, use_bias=False, use_bn=%preproc_bn)),
    "goal": torch.nn.Sequential(alf.layers.Reshape([-1]), alf.layers.FC(@flattened_size(%goal_spec), %encoding_dim, use_bias=False, use_bn=%preproc_bn)),
    "velocity": torch.nn.Sequential(alf.layers.Reshape([-1]), alf.layers.FC(@flattened_size(%velocity_spec), %encoding_dim, use_bias=False, use_bn=%preproc_bn)),
    "navigation": torch.nn.Sequential(alf.layers.Reshape([-1]), alf.layers.FC(@flattened_size(%navigation_spec), %encoding_dim, use_bias=False, use_bn=%preproc_bn)),
}

input_preprocessors={
    'observation': %observation_preprocessors,
    'prev_action': torch.nn.Sequential(alf.layers.Reshape([-1]), alf.layers.FC(@flattened_size(%prev_action_spec), %encoding_dim, use_bias=False, use_bn=%preproc_bn)),
}


import alf.environments.alf_wrappers

suite_carla.load.wrappers=[@ActionObservationWrapper]
