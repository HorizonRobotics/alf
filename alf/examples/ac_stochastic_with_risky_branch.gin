include 'ac_breakout.gin'

import alf.environments.suite_simple
create_environment.env_name="StochasticWithRiskyBranch"
create_environment.env_load_fn=@suite_simple.load
create_environment.num_parallel_environments=32

TrainerConfig.data_transformer_ctor=None

# override algorithm and training config
AdamTF.lr=1e-3

CONV_LAYER_PARAMS=None
hidden_layers=(10,)

actor/ActorDistributionNetwork.fc_layer_params=%hidden_layers
actor/ActorDistributionNetwork.conv_layer_params=%CONV_LAYER_PARAMS
CategoricalProjectionNetwork.logits_init_output_factor=1e-10

value/ValueNetwork.fc_layer_params=%hidden_layers
value/ValueNetwork.conv_layer_params=%CONV_LAYER_PARAMS

# training config
TrainerConfig.mini_batch_size=512
TrainerConfig.mini_batch_length=2
TrainerConfig.num_updates_per_train_iter=10
TrainerConfig.unroll_length=10
TrainerConfig.epsilon_greedy=0.05
TrainerConfig.initial_collect_steps=500
TrainerConfig.num_iterations=8000
TrainerConfig.num_env_steps=0
TrainerConfig.evaluate=False
TrainerConfig.num_checkpoints=1
TrainerConfig.debug_summaries=True
TrainerConfig.replay_buffer_length=200
